# Logstash pipeline configuration
# Receives logs from Filebeat, enriches them, and forwards to Elasticsearch

input {
  beats {
    port => 5044
    codec => json
  }
}

filter {
  # Extract JSON from the [VALIDATION_EVENT] prefix
  grok {
    match => { "message" => "\[VALIDATION_EVENT\] %{GREEDYDATA:validation_json}" }
  }
  
  # Parse the extracted JSON
  if [validation_json] {
    json {
      source => "validation_json"
      remove_field => ["validation_json", "message"]
    }
  }
  
  # Parse timestamp
  date {
    match => [ "@timestamp", "ISO8601" ]
    target => "@timestamp"
  }
  
  # Calculate SLA metrics (example: flag high-priority sensors)
  if [sensor_id] =~ /sensor-001/ {
    mutate {
      add_field => { "priority" => "critical" }
    }
  }
}

output {
  # Send to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "mqtt5-validation-%{+YYYY.MM.dd}"
    
    # Disable ILM for now (can enable later with proper policy)
    ilm_enabled => false
    
    # Optional: authentication
    # user => "elastic"
    # password => "changeme"
  }
  
  # Debug output (enable to see events in Logstash logs)
  stdout {
    codec => rubydebug
  }
}

